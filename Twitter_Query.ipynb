{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falahamro/twitter_harvest_academic/blob/main/Twitter_Query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1cc695",
      "metadata": {
        "id": "2c1cc695"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "=import os.path\n",
        "import stat\n",
        "import re\n",
        "import requests\n",
        "import shlex\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import csv\n",
        "from datetime import timedelta\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import tweepy\n",
        "import dateutil.parser\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309e9c0e",
      "metadata": {
        "id": "309e9c0e"
      },
      "outputs": [],
      "source": [
        "client = tweepy.Client(bearer_token = 'AAAAAAAAAAAAAAAAAAAAAH0CYgEAAAAA')\n",
        "# replace with your own search query (replace MAGA with anything else)\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    return headers\n",
        "os.environ['TOKEN'] = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f4d7d0",
      "metadata": {
        "id": "d5f4d7d0"
      },
      "outputs": [],
      "source": [
        "tweets = []\n",
        "for response in tweepy.Paginator(client.search_all_tweets, \n",
        "                                 query = 'stopthesteal -is:retweet lang:en',\n",
        "                                 user_fields = ['username', 'public_metrics','entities', 'description', 'location', 'verified'],\n",
        "                                 tweet_fields = ['id','text','author_id','in_reply_to_user_id','geo','conversation_id','created_at,lang','public_metrics','referenced_tweets','reply_settings',],\n",
        "                                 expansions = 'author_id,in_reply_to_user_id,geo.place_id,entities.mentions.username,referenced_tweets.id',\n",
        "                                 place_fields = ['full_name','id','country','country_code','geo','name','place_type',],\n",
        "                                 start_time = '2022-01-20T00:00:00Z',\n",
        "                                 end_time = '2022-04-19T00:00:00Z',\n",
        "                              max_results=500):\n",
        "    time.sleep(1)\n",
        "    tweets.append(response)\n",
        "result = []\n",
        "user_dict = {}\n",
        "# Loop through each response object\n",
        "for response in tweets:\n",
        "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
        "    for user in response.includes['users']:\n",
        "        user_dict[user.id] = {'username': user.username, \n",
        "                              'listed_count': user.public_metrics['listed_count'],\n",
        "                              'followers': user.public_metrics['followers_count'],\n",
        "                              'following': user.public_metrics['following_count'],\n",
        "                              'listed_count': user.public_metrics['listed_count'],\n",
        "\n",
        "                              'tweets': user.public_metrics['tweet_count'],\n",
        "                             #'entities': user.public_metrics['entities'],\n",
        "\n",
        "                              #'description': user.description,\n",
        "                              #'location': user.location,\n",
        "                              'verified': user.verified,\n",
        "\n",
        "                             }\n",
        "    for tweet in response.data: \n",
        "        # For each tweet, find the author's information\n",
        "        author_info = user_dict[tweet.author_id]\n",
        "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
        "        result.append({'author_id': tweet.author_id, \n",
        "                       \n",
        "                       #'geo': tweet.geo, \n",
        "                      #'referenced_tweets': tweet.referenced_tweets, \n",
        "                       #'username': author_info['username'],\n",
        "\n",
        "                       'author_followers': author_info['followers'],\n",
        "                       'author_followee': author_info['following'],\n",
        "                       'listed_count': author_info['listed_count'],\n",
        "                       'author_tweets': author_info['tweets'],\n",
        "                       #'author_description': author_info['description'],\n",
        "                       #'author_location': author_info['location'],\n",
        "                       ##author_verified': author_info['verified'],\n",
        "                       'text': tweet.text,\n",
        "                       'created_at': tweet.created_at,\n",
        "                       #'reply_settings': tweet.reply_settings,\n",
        "                       #'in_reply_to_user_id': tweet.in_reply_to_user_id,\n",
        "                       'retweets': tweet.public_metrics['retweet_count'],\n",
        "                       'replies': tweet.public_metrics['reply_count'],\n",
        "                       'likes': tweet.public_metrics['like_count'],\n",
        "\n",
        "                       'quote_count': tweet.public_metrics['quote_count'],\n",
        "                        #'favourites_count': tweet.public_metrics['favourites_count']\n",
        "\n",
        "\n",
        "                      })\n",
        "import math\n",
        "\n",
        "  \n",
        "import pandas as pd\n",
        "df = pd.DataFrame(result)\n",
        "df.to_csv('stopthesteal.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Twitter Query.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}